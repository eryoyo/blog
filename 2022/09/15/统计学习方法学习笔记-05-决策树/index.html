<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>统计学习方法学习笔记-05-决策树 - eryoyo的博客</title><link rel="manifest" href="/blog/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="eryoyo的"><meta name="msapplication-TileImage" content="/img/profile.jpeg"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="eryoyo的"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="/img/profile.jpeg"><meta name="description" content="首先介绍决策树的基本概念，然后通过$ID3$和$C4.5$介绍特征的选择、决策树的生成以及决策树的修剪，最后介绍$CART$算法"><meta property="og:type" content="blog"><meta property="og:title" content="统计学习方法学习笔记-05-决策树"><meta property="og:url" content="https://eryoyo.github.io/blog/2022/09/15/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-05-%E5%86%B3%E7%AD%96%E6%A0%91/"><meta property="og:site_name" content="eryoyo的博客"><meta property="og:description" content="首先介绍决策树的基本概念，然后通过$ID3$和$C4.5$介绍特征的选择、决策树的生成以及决策树的修剪，最后介绍$CART$算法"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://eryoyo.github.io/blog/img/og_image.png"><meta property="article:published_time" content="2022-09-15T06:53:01.000Z"><meta property="article:modified_time" content="2022-09-15T06:56:48.669Z"><meta property="article:author" content="eryoyo"><meta property="article:tag" content="统计学习方法"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/blog/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://eryoyo.github.io/blog/2022/09/15/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-05-%E5%86%B3%E7%AD%96%E6%A0%91/"},"headline":"统计学习方法学习笔记-05-决策树","image":["https://eryoyo.github.io/blog/img/og_image.png"],"datePublished":"2022-09-15T06:53:01.000Z","dateModified":"2022-09-15T06:56:48.669Z","author":{"@type":"Person","name":"eryoyo"},"publisher":{"@type":"Organization","name":"eryoyo的博客","logo":{"@type":"ImageObject","url":"https://eryoyo.github.io/img/profile.jpeg"}},"description":"首先介绍决策树的基本概念，然后通过$ID3$和$C4.5$介绍特征的选择、决策树的生成以及决策树的修剪，最后介绍$CART$算法"}</script><link rel="canonical" href="https://eryoyo.github.io/blog/2022/09/15/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-05-%E5%86%B3%E7%AD%96%E6%A0%91/"><link rel="icon" href="/blog/img/profile.jpeg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/"><img src="/blog/img/profile.jpeg" alt="eryoyo的博客" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">主页</a><a class="navbar-item" href="/blog/archives">文章</a><a class="navbar-item" href="/blog/categories">类别</a><a class="navbar-item" href="/blog/tags">标签</a><a class="navbar-item" href="/blog/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/eryoyo"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-09-15T06:53:01.000Z" title="2022/9/15 下午2:53:01">2022-09-15</time>发表</span><span class="level-item"><time dateTime="2022-09-15T06:56:48.669Z" title="2022/9/15 下午2:56:48">2022-09-15</time>更新</span><span class="level-item"><a class="link-muted" href="/blog/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></span><span class="level-item">25 分钟读完 (大约3737个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">统计学习方法学习笔记-05-决策树</h1><div class="content"><p>首先介绍决策树的基本概念，然后通过$ID3$和$C4.5$介绍特征的选择、决策树的生成以及决策树的修剪，最后介绍$CART$算法</p>
<span id="more"></span>
<h1 id="决策树模型与学习"><a href="#决策树模型与学习" class="headerlink" title="决策树模型与学习"></a>决策树模型与学习</h1><ul>
<li>分类决策树模型的树结构有两种结点，内部结点表示一个特征或属性，叶结点表示一个类；</li>
<li>决策树所有的从根节点到叶结点的路径构成<strong>if-else规则集</strong>，这些规则是互斥且完备的；</li>
<li>决策树学习算法包含特征选择、决策树的生成和决策树的修剪</li>
<li>从可能的决策树中直接选取最优决策树是$NP$完全问题，现实中采用启发式方法学习次优的决策树</li>
</ul>
<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有分类能力的，特征选择在于选取对训练数据具有分类能力的特征，特征选择的准则一般是<strong>信息增益或信息增益比</strong></p>
<h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><ul>
<li>设$X$是一个取有限个值的离散随机变量，其概率分布为$P(X &#x3D; x_i) &#x3D; p_i,i &#x3D; 1,2,\cdots,n$，则随机变量$X$的熵为：<br>$$<br>H(X) &#x3D; -\sum_{i &#x3D; 1}^np_i \log p_i<br>$$<br>熵越大，随机变量的不确定性越大，$0 \leq H(p) \leq \log n$</li>
<li>条件熵：$H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性，定义为$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望<br>$$<br>H(Y|X) &#x3D; \sum_{i &#x3D; 1}^np_iH(Y|X &#x3D; x_i)<br>$$<br>这里$p_i &#x3D; P(X &#x3D; x_i),i &#x3D; 1,2,\cdots,n$</li>
<li>信息增益表示得知特征$X$的信息而使得类$Y$的信息的不确定性减少的程度，特征$A$对训练数据集$D$的信息增益$g(D,A)$，定义为集合$D$的经验熵$H(D)$与特征$A$给定条件下$D$的经验条件熵$H(D|A)$之差：<br>$$<br>g(D,A) &#x3D; H(D) - H(D|A)<br>$$<h2 id="信息增益的算法"><a href="#信息增益的算法" class="headerlink" title="信息增益的算法"></a>信息增益的算法</h2>输入：训练数据集$D$和特征$A$<br>输出：特征$A$对训练数据集$D$的信息增益$g(D,A)$<br>设训练数据集为$D$，$|D|$表示其样本容量，即样本个数，设有$K$个类$C_k,k &#x3D; 1,2,\cdots,K,|C_k|$为属于类$C_k$的样本个数，$\sum_{k &#x3D; 1}^K|C_k| &#x3D; |D|$，设特征$A$有$n$个不同的取值${a_1,a_2,\cdots,a_n}$，根据特征$A$的取值将$D$划分为$n$个子集$D_1,D_2,\cdots,D_n$，$|D_i|$为$D_i$的样本个数，$\sum_{i &#x3D; 1}^n|D_i| &#x3D; |D|$，记子集$D_i$中属于类$C_k$的样本的集合为$D_{ik}$即$D_{ik} &#x3D; D_i \bigcap C_k,|D_{ik}|$为$D_{ik}$的样本个数</li>
<li>计算数据集$D$的经验熵$H(D)$<br>$$<br>H(D) &#x3D; -\sum_{k &#x3D; 1}^K\frac{|C_k|}{|D|}\log_2 \frac{|C_k|}{|D|}<br>$$</li>
<li>计算特征$A$对数据集$D$的经验条件熵$H(D|A)$<br>$$<br>H(D|A) &#x3D; \sum_{i &#x3D; 1}^n\frac{|D_i|}{|D|}H(D_i) &#x3D; -\sum_{i&#x3D;1}^n\frac{|D_i|}{|D|}\sum_{k&#x3D;1}^K\frac{|D_{ik}|}{|D_i|} \log_2\frac{|D_{ik}|}{|D_i|}<br>$$</li>
<li>计算信息增益<br>$$<br>g(D,A) &#x3D; H(D) - H(D|A)<br>$$</li>
</ul>
<h2 id="信息增益比"><a href="#信息增益比" class="headerlink" title="信息增益比"></a>信息增益比</h2><p>目的：以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题，使用信息增益比来校正</p>
<ul>
<li>特征$A$对训练数据集$D$的信息增益比$g_R(D,A)$定义为其信息增益$g(D,A)$与训练数据集$D$关于特征$A$的值的熵$H_A(D)$之比<br>$$<br>\begin{aligned}<br>g_R(D,A) &amp;&#x3D; \frac{g(D,A)}{H_A(D)} \<br>&amp;&#x3D; \frac{g(D,A)}{-\sum_{i &#x3D; 1}^n\frac{|D_i|}{D} \log_2 \frac{|D_i|}{D}}<br>\end{aligned}<br>$$</li>
</ul>
<h1 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h1><h2 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h2><p>输入：训练数据集$D$，特征集$A$，阈值$\varepsilon$<br>输出：决策树$T$</p>
<ul>
<li>若$D$中所有实例属于同一类$C_k$，则$T$为单结点树，并将类$C_k$作为该结点的类标记，返回$T$;</li>
<li>若$A &#x3D; \emptyset$，则$T$为单结点树，并将$D$中实例数最大的类$C_k$作为该结点的类标记，返回$T$;</li>
<li>否则计算各特征对$D$的信息增益，选择信息增益最大的特征$A_g$</li>
<li>如果$A_g$的信息增益小于阈值$\varepsilon$，则置$T$为单结点树，并将$D$中实例数最大的类$C_k$作为该结点的类标记，返回$T$;</li>
<li>否则，对$A_g$的每一个可能取值$a_i$，依$A_g &#x3D; a_i$将$D$分割为非空子集$D_i$，将$D_i$中实例数最大的类作为标记，构建子结点，由结点及其子结点构成树$T$，返回$T$；</li>
<li>对第$i$个子结点，以$D_i$为训练集，以$A-{A_g}$为特征集，递归的调用第一步到第五步，得到子树$T_i$，返回$T_i$</li>
</ul>
<h2 id="C4-5生成算法"><a href="#C4-5生成算法" class="headerlink" title="C4.5生成算法"></a>C4.5生成算法</h2><p>输入：训练数据集$D$，特征集$A$，阈值$\varepsilon$<br>输出：决策树$T$</p>
<ul>
<li>若$D$中所有实例属于同一类$C_k$，则$T$为单结点树，并将类$C_k$作为该结点的类标记，返回$T$;</li>
<li>若$A &#x3D; \emptyset$，则$T$为单结点树，并将$D$中实例数最大的类$C_k$作为该结点的类标记，返回$T$;</li>
<li>否则计算各特征对$D$的信息增益比，选择信息增益比最大的特征$A_g$</li>
<li>如果$A_g$的信息增益比小于阈值$\varepsilon$，则置$T$为单结点树，并将$D$中实例数最大的类$C_k$作为该结点的类标记，返回$T$;</li>
<li>否则，对$A_g$的每一个可能取值$a_i$，依$A_g &#x3D; a_i$将$D$分割为非空子集$D_i$，将$D_i$中实例数最大的类作为标记，构建子结点，由结点及其子结点构成树$T$，返回$T$；</li>
<li>对第$i$个子结点，以$D_i$为训练集，以$A-{A_g}$为特征集，递归的调用第一步到第五步，得到子树$T_i$，返回$T_i$</li>
</ul>
<h1 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a>决策树的剪枝</h1><p>目的：解决过拟合问题</p>
<h2 id="剪枝时的损失函数"><a href="#剪枝时的损失函数" class="headerlink" title="剪枝时的损失函数"></a>剪枝时的损失函数</h2><p>设树$T$的叶结点个数为$|T|$，$t$是树$T$的叶结点，该叶结点有$N_t$个样本点，其中$k$类的样本点有$N_{tk}$个，$k &#x3D; 1,2,\cdots,K$，$H_t(T)$为叶结点$t$上的经验熵，$\alpha \geq 0$为参数，则决策树学习的损失函数可以定义为：<br>$$<br>C_\alpha(T) &#x3D; \sum_{t &#x3D; 1}^{|T|}N_tH_t(T) + \alpha|T|<br>$$<br>其中经验熵为：<br>$$<br>H_t(T) &#x3D; -\sum_k\frac{N_{tk}}{N_t}\log \frac{N_{tk}}{N_t}<br>$$<br>将式子左边记为：<br>$$<br>C(T) &#x3D; \sum_{t &#x3D; 1}^{|T|}N_tH_t(T) &#x3D; -\sum_{t &#x3D; 1}^{|T|}\sum_{k &#x3D; 1}^KN_{tk} \log \frac{N_{tk}}{N_t}<br>$$<br>有：<br>$$<br>C_\alpha(T) &#x3D; C(T) + \alpha|T|<br>$$<br>$C(T)$表示模型对训练数据的预测误差，即模型与训练数据的拟合程度，$|T|$表示模型复杂度，参数$\alpha$控制两者之间的影响，较大促使选择较简单的模型，较小促使选择较复杂的模型</p>
<h2 id="树的剪枝算法"><a href="#树的剪枝算法" class="headerlink" title="树的剪枝算法"></a>树的剪枝算法</h2><p>当$\alpha$确定时，选择损失函数最小的模型<br>输入：生成算法产生的整个树$T$，参数$\alpha$；<br>输出：修剪后的子树$T_\alpha$</p>
<ul>
<li>计算每个结点的经验熵</li>
<li>递归的从树的叶结点向上回缩，设一组叶结点回缩到其父结点之前与之后的整体树分别为$T_B$与$T_A$，其对应的损失函数分别是$C_\alpha(T_B)$与$C_\alpha(T_A)$，如果$C_\alpha(T_B) \leq C_\alpha(T_A)$，则进行剪枝，即将父结点变为新的叶结点。</li>
<li>返回第二步，直到不能继续为止，得到损失函数最小的子树$T_{\alpha}$</li>
</ul>
<h1 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h1><p>classification and regression tree分类与回归树模型</p>
<ul>
<li>决策树生成：基于训练数据集生成决策树，生成的决策树要尽量大；</li>
<li>决策树剪枝：用验证数据集对已生成的树进行剪枝并选择最优子树，这时用损失函数最小作为剪枝的标准；</li>
</ul>
<h2 id="回归树的生成"><a href="#回归树的生成" class="headerlink" title="回归树的生成"></a>回归树的生成</h2><p>假设输入$X$与$Y$分别为输入和输出变量，并且$Y$是连续变量，给定训练数据集$D &#x3D; {(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}$<br>输入：训练数据集$D$;<br>输出：回归树$f(x)$，对应着将特征空间划分为$M$个单元$R_1,R_2,\cdots,R_M$，在每个单元上有一个固定的输出值$c_m$;</p>
<ul>
<li>选择最优切分变量$j$与切分点$s$，求解<br>$$<br>\mathop{min}\limits_{j,s}<br>\left[<br>\mathop{min}\limits_{c_1}\sum_{x_i \in R_1(j,s)}(y_i - c_1)^2 +<br>\mathop{min}\limits_{c_2}\sum_{x_i \in R_2(j,s)}(y_i - c_2)^2<br>\right]<br>$$<br>选择第$j$个变量$x^{(j)}$和它取的值$s$作为切分变量和切分点，定义两个区域$R_1(j,s) &#x3D; {x|x^{(j)} \leq s},R_2(j,s) &#x3D; {x|x^{(j)} \gt s}$,遍历变量$j$，对固定的切分变量$j$扫描切分点$s$，选择使上式达到最小值的对$(j,s)$</li>
<li>用选定的对$(j,s)$划分区域并决定相应的输出值：<br>$$<br>R_1(j,s) &#x3D; {x|x^{(j)} \leq s},R_2(j,s) &#x3D; {x|x^{(j)} \gt s} \<br>\hat{c}<em>m &#x3D; \frac{1}{N_m}\sum</em>{x_i \in R_m(j,s)}y_i,x \in R_m,m&#x3D;1,2<br>$$</li>
<li>继续对两个子区域调用步骤1,2，直到满足停止条件；</li>
<li>将输入空间划分为$M$个区域$R_1,R_2,\cdots,R_M$，生成决策树：<br>$$<br>f(x) &#x3D; \sum_{m &#x3D; 1}^M\hat{c}_mI(x \in R_m)<br>$$</li>
</ul>
<h2 id="分类树的生成"><a href="#分类树的生成" class="headerlink" title="分类树的生成"></a>分类树的生成</h2><p>分类树使用基尼指数选择最优特征，同时决定该特征的最优二值切分点</p>
<h3 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h3><p>分类问题中，假设有$K$个类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义：<br>$$<br>Gini(p) &#x3D; \sum_{k &#x3D; 1}^Kp_k(1-p_k) &#x3D; 1 - \sum_{k &#x3D; 1}^Kp_k^2<br>$$<br>对于给定的样本集合$D$，其基尼指数为：<br>$$<br>Gini(D) &#x3D; 1 - \sum_{k &#x3D; 1}^K\left(\frac{|C_k|}{|D|}\right)^2<br>$$<br>$C_k$是$D$中属于第$k$类的样本子集，$K$是类的个数。<br>如果样本集合$D$根据特征$A$是否取某一可能值$a$被分割成$D_1$和$D_2$两部分，即：<br>$$<br>D_1 &#x3D; {(x,y) \in D|A(x) &#x3D; a},D_2 &#x3D; D - D_1<br>$$<br>则在特征$A$的条件下，集合$D$的基尼指数定义为：<br>$$<br>Gini(D,A) &#x3D; \frac{|D_1|}{|D|}Gini(D_1) + \frac{|D_2|}{|D|}Gini(D_2)<br>$$<br>基尼指数$Gini(D)$表示集合$D$的不确定性，基尼指数$Gini(D,A)$表示经$A &#x3D; a$分割后集合$D$的不确定性，基尼指数值越大，样本集合的不确定性越大。</p>
<h2 id="CART生成算法"><a href="#CART生成算法" class="headerlink" title="CART生成算法"></a>CART生成算法</h2><p>输入：训练数据集$D$，停止计算的条件；<br>输出：CART决策树；</p>
<ul>
<li>设节点的训练数据集为$D$，计算现有特征对该数据集的基尼指数，此时，对每一个特征$A$，对其可能取的每个值$a$，根据样本点对$A &#x3D; a$的测试为“是”或“否”将$D$分割成$D_1$和$D_2$两部分，计算$A &#x3D; a$的基尼指数</li>
<li>在所有可能额特征$A$以及它们所有可能的切分点$a$中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。依最优特征与最优切分点，从现有结点生成两个子结点，将训练数据集依特征分配到两个子结点中去；</li>
<li>对两个子结点递归的调用1,2步，直至满足停止条件</li>
<li>生成CART决策树<br>算法停止计算的条件是节点中的样本个数小于预定阈值，或样本集的基尼指数小于预定阈值(样本基本属于同一类)，或者没有更多特征。</li>
</ul>
<h2 id="CART剪枝"><a href="#CART剪枝" class="headerlink" title="CART剪枝"></a>CART剪枝</h2><p>首先从生成算法产生的决策树$T_0$底端开始不断剪枝，直到$T_0$的根结点，形成一个子树序列${T_0,T_1,\cdots,T_n}$，之后通过交叉验证法在独立的验证数据集上对子树序列进行测试，从中选择最优子树</p>
<h3 id="剪枝，形成一个子树序列"><a href="#剪枝，形成一个子树序列" class="headerlink" title="剪枝，形成一个子树序列"></a>剪枝，形成一个子树序列</h3><ul>
<li>子树的损失函数：<br>$$<br>C_\alpha(T) &#x3D; C(T) + \alpha|T|<br>$$</li>
<li>对整体树$T_0$开始剪枝，对$T_0$的任意内部结点$t$，以$t$为单结点树的损失函数是：<br>$$<br>C_\alpha(t) &#x3D; C(t) + \alpha<br>$$</li>
<li>以$t$为根结点的子树$T_t$的损失函数是：<br>$$<br>C_\alpha(T_t) &#x3D; C(T_t) + \alpha|T_t|<br>$$</li>
<li>当$\alpha  &#x3D; 0$时，有不等式：<br>$$<br>C_\alpha(T_t) &#x3D; C_\alpha(t)<br>$$</li>
<li>当$\alpha$不断增大时，不等式反向</li>
<li>在$\alpha &#x3D; \frac{C(t) - C(T_t)}{|T_t| - 1}$时，$T_t$和$t$有相同的损失函数值，也就是单个节点的损失函数值和一颗子树的损失函数值相同，所以这课子树可以被剪掉</li>
<li>对$T_0$中的每一个内部结点进行计算：<br>$$<br>g(t) &#x3D; \frac{C(t) - C(T_t)}{|T_t| - 1}<br>$$<br>在$T_0$中减去$g(t)$最小的子树$T_t$，将得到的子树作为$T_1$，同时将最小的$g(t)$设为$\alpha_1$，$T_1$为区间$[\alpha_1,\alpha_2)$的最优子树，如此剪枝下去，不断增加$\alpha$的值，产生了新的区间。</li>
</ul>
<h3 id="在剪枝得到的子树序列中通过交叉验证选取最优子树"><a href="#在剪枝得到的子树序列中通过交叉验证选取最优子树" class="headerlink" title="在剪枝得到的子树序列中通过交叉验证选取最优子树"></a>在剪枝得到的子树序列中通过交叉验证选取最优子树</h3><ul>
<li>使用独立的验证数据集，测试子树序列$T_0,T_1,\cdots,T_n$中各棵子树的平方误差或基尼指数</li>
<li>平方误差或基尼指数最小的决策树被称为最优的决策树$T_\alpha$</li>
<li>子树和$\alpha$是一一对应的</li>
</ul>
<h3 id="CART剪枝算法"><a href="#CART剪枝算法" class="headerlink" title="CART剪枝算法"></a>CART剪枝算法</h3><p>输入：CART算法生成的决策树$T_0$<br>输出：最优决策树$T_\alpha$</p>
<ul>
<li>设$k &#x3D; 0,T &#x3D; T_0$；</li>
<li>设$\alpha &#x3D; +\infty$；</li>
<li>自下而上的对各内部节点$t$计算:<br>$$<br>g(t) &#x3D; \frac{C(t) - C(T_t)}{|T_t| - 1} \<br>\alpha &#x3D; min(\alpha,g(t))<br>$$</li>
<li>对$g(t) &#x3D; \alpha$的内部结点$t$进行剪枝，并对叶结点$t$以多数表决法决定其类，得到树$T$；</li>
<li>设$k &#x3D; k + 1, \alpha_k &#x3D; \alpha,T_k &#x3D; T$；</li>
<li>如果$T_k$不是由根结点及两个叶结点构成的树，则回到第二步，否则$T_k &#x3D; T_n$；</li>
<li>采用交叉验证法在子树序列$T_0,T_1,\cdots,T_n$中选取最优子树$T_\alpha$；</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>统计学习方法学习笔记-05-决策树</p><p><a href="https://eryoyo.github.io/blog/2022/09/15/统计学习方法学习笔记-05-决策树/">https://eryoyo.github.io/blog/2022/09/15/统计学习方法学习笔记-05-决策树/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>eryoyo</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2022-09-15</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-09-15</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></div><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_telegram"></a><a class="a2a_button_whatsapp"></a><a class="a2a_button_reddit"></a></div><script src="https://static.addtoany.com/menu/page.js" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/blog/" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/blog/" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/2022/09/15/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-06-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B01/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">统计学习方法学习笔记-06-逻辑斯谛回归与最大熵模型01</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2022/09/14/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-04-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/"><span class="level-item">统计学习方法学习笔记-04-朴素贝叶斯法</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://eryoyo.github.io/blog/2022/09/15/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-05-%E5%86%B3%E7%AD%96%E6%A0%91/';
            this.page.identifier = '2022/09/15/统计学习方法学习笔记-05-决策树/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'blog-eryoyo' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/blog/img/profile.jpeg" alt="eryoyo"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">eryoyo</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>北京</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/blog/archives"><p class="title">66</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/blog/categories"><p class="title">13</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/blog/tags"><p class="title">14</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/eryoyo" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/eryoyo"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Zhihu" href="https://www.zhihu.com/people/er-yo-49"><i class="fab fa-zhihu"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Csdn" href="https://blog.csdn.net/weixin_44994838"><i class="fab fa-drupal"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/categories/linux/"><span class="level-start"><span class="level-item">linux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E4%B8%AA%E4%BA%BA%E5%B0%8F%E8%AE%B0/"><span class="level-start"><span class="level-item">个人小记</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">刷题笔记</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E5%8D%9C%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">卜算法</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">图像处理</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%9D%8E%E5%AE%8F%E6%AF%85/"><span class="level-start"><span class="level-item">机器学习-李宏毅</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">模式识别与机器学习</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"><span class="level-start"><span class="level-item">离散数学</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"><span class="level-start"><span class="level-item">统计学习方法</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E7%BD%91%E7%AB%99%E5%88%9B%E5%BB%BA/"><span class="level-start"><span class="level-item">网站创建</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E8%AE%BA%E6%96%87/"><span class="level-start"><span class="level-item">论文</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"><span class="level-start"><span class="level-item">高级人工智能</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-23T15:04:19.000Z">2022-10-23</time></p><p class="title"><a href="/blog/2022/10/23/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-lecture08-%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90/">自然语言处理学习笔记-lecture08-语义分析</a></p><p class="categories"><a href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-21T13:27:13.000Z">2022-10-21</time></p><p class="title"><a href="/blog/2022/10/21/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-lecture07-%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%9001/">自然语言处理学习笔记-lecture07-句法分析01</a></p><p class="categories"><a href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-21T09:09:30.000Z">2022-10-21</time></p><p class="title"><a href="/blog/2022/10/21/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-lecture06-%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8/">自然语言处理学习笔记-lecture06-词法分析与词性标注</a></p><p class="categories"><a href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-21T05:31:25.000Z">2022-10-21</time></p><p class="title"><a href="/blog/2022/10/21/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-lecture5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B03/">自然语言处理学习笔记-lecture5-语言模型03</a></p><p class="categories"><a href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-20T12:37:33.000Z">2022-10-20</time></p><p class="title"><a href="/blog/2022/10/20/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-lecture5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B02/">自然语言处理学习笔记-lecture5-语言模型02</a></p><p class="categories"><a href="/blog/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/archives/2022/10/"><span class="level-start"><span class="level-item">十月 2022</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2022/09/"><span class="level-start"><span class="level-item">九月 2022</span></span><span class="level-end"><span class="level-item tag">37</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2022/08/"><span class="level-start"><span class="level-item">八月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2022/05/"><span class="level-start"><span class="level-item">五月 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2022/04/"><span class="level-start"><span class="level-item">四月 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/icarus/"><span class="tag">icarus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/makefile/"><span class="tag">makefile</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><span class="tag">图像处理</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E5%9F%BA%E7%A1%80/"><span class="tag">基础</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"><span class="tag">模式识别</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"><span class="tag">离散数学</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"><span class="tag">统计学习方法</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="tag">自然语言处理</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E8%AE%BA%E6%96%87/"><span class="tag">论文</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"><span class="tag">高级人工智能</span><span class="tag">2</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/"><img src="/blog/img/profile.jpeg" alt="eryoyo的博客" height="28"></a><p class="is-size-7"><span>&copy; 2022 eryoyo</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/eryoyo"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/blog/js/column.js"></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>